{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. MLP.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","authorship_tag":"ABX9TyNBoMBCVOGDd/jHvTf+hzJl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KJT5kqyZGe1p"},"source":["# Multi-layer Perceptron (MLP)"]},{"cell_type":"markdown","metadata":{"id":"NzHP2rndF-0G"},"source":["## 외부 파일 가져오기 & requirements 설치"]},{"cell_type":"code","metadata":{"id":"Mi95dewjGeW_"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD7vyST9GdHv"},"source":["import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import random_split\n","\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QX3soatAMk5B"},"source":["from data_utils import dataset_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lISGUqfUG_Ny"},"source":["data_root = os.path.join(os.getcwd(), \"data\")\n","\n","# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n","transform = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5], [0.5]), # mean, # std\n","    ]\n",")\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0waoPp23NcE0"},"source":["## Dataloader를 정의"]},{"cell_type":"code","metadata":{"id":"A5Nq1tZiJ84g"},"source":["datasets = dataset_split(fashion_mnist_dataset, split=[0.9, 0.1])\n","\n","train_dataset = datasets[\"train\"]\n","val_dataset = datasets[\"val\"]\n","\n","train_batch_size = 100\n","val_batch_size = 10\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=1\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKRCanL6LtoM"},"source":["for sample_batch in train_dataloader:\n","    print(sample_batch)\n","    print(sample_batch[0].shape, sample_batch[1].shape)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lwd5nW_3N37z"},"source":["## 모델 (Multi-layer Perceptron) (MLP) ! 정의"]},{"cell_type":"code","metadata":{"id":"-O--VMLMN04F"},"source":["# Define Model.\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","        self.relu = F.relu\n","        \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8tljBSaQBZB"},"source":["## 모델 선언 및 손실 함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의 "]},{"cell_type":"code","metadata":{"id":"z8p_hsjsO-on"},"source":["# define model.\n","model = MLP(28*28, 128, 64, 10)\n","\n","# define loss\n","loss_function = nn.CrossEntropyLoss()\n","\n","# define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","max_epoch = 15\n","\n","# define tensorboard logger\n","writer = SummaryWriter()\n","log_interval = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oq-XpcGXQu1v"},"source":["%load_ext tensorboard\n","%tensorboard --logdir runs/\n","\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n","    )\n","    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n","    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n","    writer.add_images(\"Images/val\", val_images, train_step)\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % log_interval == 0:\n","            train_loss = current_loss / log_interval\n","            train_acc = current_corrects / log_interval\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n","            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n","            writer.add_images(\"Images/train\", images, train_step)\n","            writer.add_graph(model, images)\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1oxnXSyQ2b7"},"source":["# save model\n","os.makedirs(\"./logs/models\", exist_ok=True)\n","torch.save(model, \"./logs/models/mlp.ckpt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymnDN1VkYOvt"},"source":["# load model\n","loaded_model = torch.load(\"./logs/models/mlp.ckpt\")\n","loaded_model.eval()\n","print(loaded_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHvB9xAnYWBk"},"source":["def softmax(x, axis=0):\n","    \"numpy softmax\"\n","    max = np.max(x, axis=axis, keepdims=True)\n","    e_x = np.exp(x - max)\n","    sum = np.sum(e_x, axis=axis, keepdims=True)\n","    f_x = e_x / sum\n","    return f_x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UoTf2ztY7nT"},"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().numpy())\n","    test_labels_list.extend(test_labels.detach().numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0a4PPefaRfH"},"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm5jZ7urbMAO"},"source":[""],"execution_count":null,"outputs":[]}]}