{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05-3. Pytorch-lightning & Hydra, CNN","private_outputs":true,"provenance":[{"file_id":"1erxCNSOQW7VIAG2BHeIn3JT8c7meNa7T","timestamp":1628854419947},{"file_id":"1Z45RhZD6DFfZgDsoSGZhYKoAhgf4szLf","timestamp":1628427684925},{"file_id":"1vOwqGgv4OKk-1vYWcH8uFpvoIooaUeTj","timestamp":1628424146619},{"file_id":"1n37-PsBNU1tEXNwUvWohvHVJD81-C8m2","timestamp":1627212638626},{"file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","timestamp":1626696451891}],"collapsed_sections":[],"mount_file_id":"1gNh-HsjMOM_aMXda7EfQdjZjqAA3DNqt","authorship_tag":"ABX9TyPRvzFH1Um/XTl3NOQYNHaj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KJT5kqyZGe1p"},"source":["# Fashion Mnist DNN Tutorial [CNN & Multi-layer Perceptron (MLP)]"]},{"cell_type":"markdown","metadata":{"id":"NzHP2rndF-0G"},"source":["## 외부 파일 가져오기 & requirements 설치"]},{"cell_type":"code","metadata":{"id":"Mi95dewjGeW_"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","import sys\n","from datetime import datetime\n","\n","drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n","sys.path.append(drive_project_root)\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFlvgHkj2wzZ"},"source":["gpu_info = !nvidia-smi\n","gpu_info = \"\\n\".join(gpu_info)\n","print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9djS-LtvmwC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD7vyST9GdHv"},"source":["from abc import abstractmethod\n","from typing import Optional\n","from typing import Dict\n","from typing import List\n","from typing import Union\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from omegaconf import OmegaConf\n","from omegaconf import DictConfig\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","import pytorch_lightning as pl\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch_optimizer import RAdam\n","from torch_optimizer import AdamP\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import random_split\n","from torchvision.datasets import FashionMNIST\n","from torchvision import transforms\n","import wandb\n","\n","from efficientnet_pytorch import EfficientNet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QX3soatAMk5B"},"source":["from data_utils import dataset_split\n","from config_utils import flatten_dict\n","from config_utils import register_config\n","from config_utils import configure_optimizers_from_cfg\n","from config_utils import get_loggers\n","from config_utils import get_callbacks\n","from custom_math import softmax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lwd5nW_3N37z"},"source":["## 모델 (Multi-layer Perceptron) (MLP) ! 정의\n","## 모델 MLPWithDropout 정의\n"]},{"cell_type":"code","metadata":{"id":"vNBF3WY_Z0rY"},"source":["class BaseLightningModule(pl.LightningModule):\n","    def __init__(self, cfg: DictConfig):\n","        pl.LightningModule.__init__(self)\n","        self.cfg = cfg\n","        self.loss_function = nn.CrossEntropyLoss()\n","    \n","    @abstractmethod\n","    def forward(self, x):\n","        raise NotImplementedError()\n","    \n","    def configure_optimizers(self):\n","        self._optimizers, self._schedulers = configure_optimizers_from_cfg(self.cfg, self)\n","        return self._optimizers, self._schedulers\n","    \n","    def _forward(self, images, labels, mode: str):\n","\n","        assert mode in [\"train\", \"val\", \"test\"]\n","\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","\n","        # get loss (Loss 계산)\n","        loss = self.loss_function(outputs, labels)\n","        corrects = torch.sum(preds == labels.data)\n","        acc = corrects / len(outputs)\n","\n","        return {\n","            f\"{mode}_loss\": loss,\n","            f\"{mode}_acc\": acc,\n","        }, {\n","            f\"{mode}_outputs\": outputs,\n","            f\"{mode}_preds\": preds,\n","            f\"{mode}_images\": images,\n","            f\"{mode}_labels\": labels,\n","            f\"{mode}_corrects\": corrects,\n","        }\n","\n","    \n","    def training_step(self, batch, batch_idx):\n","        images, labels = batch\n","        logs, _ = self._forward(images, labels, mode=\"train\")\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"train_loss\"]\n","        return logs\n","    \n","    def validation_step(self, batch, batch_idx):\n","        images, labels = batch\n","        logs, _ = self._forward(images, labels, mode=\"val\")\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"val_loss\"]\n","        return logs\n","    \n","    def test_step(self, batch, batch_idx):\n","        images, labels = batch\n","        logs, logs_detail = self._forward(images, labels, mode=\"test\")\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"test_loss\"]\n","        logs.update(logs_detail)\n","        return logs\n","    \n","    def test_epoch_end(self, step_end_outputs):\n","        \n","        model_outputs = torch.cat([o[\"test_outputs\"] for o in step_end_outputs]).detach().cpu().numpy()\n","        labels = torch.cat([o[\"test_labels\"] for o in step_end_outputs]).detach().cpu().numpy()\n","        preds = torch.cat([o[\"test_preds\"] for o in step_end_outputs]).detach().cpu().numpy()\n","        corrects = torch.cat([o[\"test_corrects\"] for o in step_end_outputs]).detach().cpu().numpy()\n","        losses = torch.cat([o[\"test_loss\"] for o in step_end_outputs]).detach().cpu().numpy()\n","\n","        final_outs = softmax(model_outputs, axis=1)\n","\n","        fpr = {}\n","        tpr = {}\n","        thresh = {}\n","        n_class = self.cfg.data.n_class\n","\n","        for i in range(n_class):\n","            fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, model_outputs[:, i], pos_label=i)\n","\n","        # plot.\n","        for i in range(n_class):\n","            plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","        plt.title(\"Multi-class ROC Curve\")\n","        plt.xlabel(\"False Positive Rate\")\n","        plt.ylabel(\"True Positive Rate\")\n","        plt.legend(loc=\"best\")\n","        # plt.show()\n","\n","        auc_score = roc_auc_score(\n","            test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"\n","        )\n","\n","        acc = corrects / len(corrects)\n","        mean_loss = np.mean(losses)\n","\n","        return {\n","            \"test_auc_score\": auc_score,\n","            \"test_accuracy\": acc,\n","            \"test_loss\": mean_loss\n","        }\n","    \n","# TODO: add below things in the configs.\n","# cfg.data.n_class\n","# cfg.opt.lr_schedulers\n","# cfg.opt.optimizers "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-O--VMLMN04F"},"source":["# Define Model.\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.linear1 = nn.Linear(in_dim, h1_dim)\n","        self.linear2 = nn.Linear(h1_dim, h2_dim)\n","        self.linear3 = nn.Linear(h2_dim, out_dim)\n","        self.relu = F.relu\n","        pass\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n","\n","class PLMLP(BaseLightningModule):\n","    def __init__(self, cfg: DictConfig):\n","        BaseLightningModule.__init__(self, cfg=cfg)\n","        self.linear1 = nn.Linear(cfg.model.in_dim, cfg.model.h1_dim)\n","        self.linear2 = nn.Linear(cfg.model.h1_dim, cfg.model.h2_dim)\n","        self.linear3 = nn.Linear(cfg.model.h2_dim, cfg.model.out_dim)\n","        self.relu = F.relu\n","        pass\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n","\n","\n","class MLPWithDropout(MLP):\n","    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n","        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n","        self.dropout1 = nn.Dropout(dropout_prob)\n","        self.dropout2 = nn.Dropout(dropout_prob)\n","    \n","    def forward(self, input):\n","        x = torch.flatten(input, start_dim=1)\n","        x = self.relu(self.linear1(x))\n","        x = self.dropout1(x)\n","        x = self.relu(self.linear2(x))\n","        x = self.dropout2(x)\n","        out = self.linear3(x)\n","        # out = F.softmax(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"42in1xpAqQDY"},"source":["## CNN 모델 정의"]},{"cell_type":"code","metadata":{"id":"dCEx_VgEqTiB"},"source":["_cnn_cfg_dict: dict = {\n","    \"layer_1\": {\n","        \"conv2d_in_channels\": 1,\n","        \"conv2d_out_channels\": 32,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 1,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 2,\n","    },\n","    \"layer_2\": {\n","        \"conv2d_in_channels\": 32,\n","        \"conv2d_out_channels\": 64,\n","        \"conv2d_kernel_size\": 3,\n","        \"conv2d_padding\": 0,\n","        \"maxpool2d_kernel_size\": 2,\n","        \"maxpool2d_stride\": 1,\n","    },\n","    \"fc_1\": {\n","        \"in_features\": 2304, #  수정 필요!\n","        \"out_features\": 512,\n","    },\n","    \"fc_2\": {\n","        \"in_features\": 512,\n","        \"out_features\": 128,        \n","    },\n","    \"fc_3\": {\n","        \"in_features\": 128,\n","        \"out_features\": 10,\n","    },\n","    \"dropout_prob\": 0.25,\n","}\n","_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n","print(OmegaConf.to_yaml(_cnn_cfg))\n","\n","class CNN(nn.Module):\n","    def __init__(self, cfg: DictConfig = _cnn_cfg):\n","        super().__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_1.conv2d_in_channels,\n","                out_channels=cfg.layer_1.conv2d_out_channels,\n","                kernel_size=cfg.layer_1.conv2d_kernel_size,\n","                padding=cfg.layer_1.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n","                stride=cfg.layer_1.maxpool2d_kernel_size\n","            )\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=cfg.layer_2.conv2d_in_channels,\n","                out_channels=cfg.layer_2.conv2d_out_channels,\n","                kernel_size=cfg.layer_2.conv2d_kernel_size,\n","                padding=cfg.layer_2.conv2d_padding\n","            ),\n","            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n","            nn.ReLU(),\n","            nn.MaxPool2d(\n","                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n","                stride=cfg.layer_2.maxpool2d_kernel_size\n","            )\n","        )\n","        self.fc1 = nn.Linear(\n","            in_features=cfg.fc_1.in_features,\n","            out_features=cfg.fc_1.out_features,\n","        )\n","        self.fc2 = nn.Linear(\n","            in_features=cfg.fc_2.in_features,\n","            out_features=cfg.fc_2.out_features,\n","        )\n","        self.fc3 = nn.Linear(\n","            in_features=cfg.fc_3.in_features,\n","            out_features=cfg.fc_3.out_features,\n","        )\n","        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n","\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.dropout(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVNk_qol3eCz"},"source":["_efficient_finetune_cfg_dict: dict = {\n","    \"efficient_net_model_name\": \"efficientnet-b1\",\n","    \"num_classes\": 10\n","}\n","_efficient_finetune_cfg_cfg = OmegaConf.create(_efficient_finetune_cfg_dict)\n","print(OmegaConf.to_yaml(_efficient_finetune_cfg_cfg))\n","\n","class EfficientNetFinetune(nn.Module):\n","    def __init__(self, cfg: DictConfig = _efficient_finetune_cfg_cfg):\n","        super().__init__()\n","        self.efficientnet = EfficientNet.from_pretrained(\n","            cfg.efficient_net_model_name,\n","            cfg.num_classes\n","        )\n","    \n","    def forward(self, x):\n","        out = self.efficientnet(x)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMzKfPjHjQLb"},"source":["# transform = transforms.Compose(\n","#     [\n","#         transforms.Resize(224),\n","#         transforms.ToTensor(),\n","#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n","#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","#     ]\n","# )\n","\n","\n","\n","# data configs\n","data_fashion_mnist_cfg = {\n","    \"name\": \"fashion_mnist\",\n","    \"data_root\": os.path.join(os.getcwd(), \"data\"),\n","    \"W\": 28,\n","    \"H\": 28,\n","    \"C\": 1,\n","    \"n_class\": 10,\n","}\n","\n","# model configs \n","model_mnist_mlp_cfg = {\n","    \"name\": \"MLP\",\n","    \"in_dim\": 28*28,\n","    \"h1_dim\": 128,\n","    \"h2_dim\": 64,\n","    \"out_dim\": 10,\n","    \"feature\": {\n","        \"normalize\": {\n","            \"mean\": [0.5],\n","            \"std\": [0.5],\n","        }\n","    }\n","}\n","\n","# optimizer configs\n","opt_cfg = {\n","    \"optimizers\": [\n","        {\n","            \"name\": \"RAdam\",\n","            \"kwargs\": {\n","                \"lr\": 1e-3,\n","                \"betas\": (0.9, 0.999),\n","                \"eps\": 1e-8,\n","                \"weight_decay\": 0,\n","            },\n","        }\n","    ],\n","    \"lr_schedulers\": [\n","        {\n","            \"name\": None,\n","            \"kwargs\": {}\n","        }\n","    ]\n","}\n","\n","_merged_cfg_presets = {\n","    \"mlp_fashion_mnist\": {\n","        \"data\": data_fashion_mnist_cfg,\n","        \"model\": model_mnist_mlp_cfg,\n","        \"opt\": opt_cfg, \n","    },\n","}\n","\n","### hydra composition ###\n","# clear hydra instance first\n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","\n","# initializing\n","hydra.initialize(config_path=None)\n","\n","# compose\n","cfg = hydra.compose(\"mlp_fashion_mnist\")\n","\n","###\n","\n","# override some cfg \n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n","\n","\n","## Define train configs\n","project_root_dir = os.path.join(\n","    drive_project_root, \"runs\", \"dnn-tutorial-fashion-mnist-runs\"\n",")\n","save_dir = os.path.join(project_root_dir, run_name)\n","run_root_dir = os.path.join(project_root_dir, run_name)\n","\n","# train configs\n","train_cfg = {\n","    \"train_batch_size\": 128,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"train_val_split\": [0.9, 0.1],\n","    \"run_root_dir\": run_root_dir,\n","    \"trainer_kwargs\": {\n","        \"accelerator\": \"dp\",\n","        \"gpus\": \"0\",\n","        \"max_epochs\": 50,\n","        \"val_check_interval\": 1.0,\n","        \"log_every_n_steps\": 100,\n","        \"flush_logs_every_n_steps\": 100,\n","    }\n","}\n","\n","# logger configs \n","log_cfg = {\n","    \"loggers\": {\n","        \"WandbLogger\": {\n","            \"project\": \"fastcampus_fashion_mnist_tutorials\",\n","            \"name\": run_name,\n","            \"tags\": [\"fastcampus_fashion_mnist_tutorials\"],\n","            \"save_dir\": run_root_dir,\n","        },\n","        \"TensorBoardLogger\": {\n","            \"save_dir\": project_root_dir,\n","            \"name\": run_name,\n","        }\n","    },\n","    \"callbacks\": {\n","        \"ModelCheckpoint\": {\n","            \"save_top_k\": 3,\n","            \"monitor\": \"val_loss\",\n","            \"mode\": \"min\",\n","            \"verbose\": True,\n","            \"dirpath\": os.path.join(run_root_dir, \"weights\"),\n","            \"filename\": \"{epoch}-{val_loss:.3f}-{val_acc:.3f}\"\n","        },\n","        \"EarlyStopping\": {\n","            \"monitor\": \"val_loss\",\n","            \"mode\": \"min\",\n","            \"patience\": 3,\n","            \"verbose\": True,\n","        }\n","    }\n","}\n","\n","# unlock config & set train, log confg\n","OmegaConf.set_struct(cfg, False)\n","cfg.train = train_cfg\n","cfg.log = log_cfg\n","\n","# lock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NOm5_pPsQwx"},"source":["data_root = cfg.data.data_root\n","\n","# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n","transform = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            cfg.model.feature.normalize.mean,\n","            cfg.model.feature.normalize.std,\n","        ), # mean, # std\n","    ]\n",")\n","\n","# transform = transforms.Compose(\n","#     [\n","#         transforms.Resize(cfg.data.W*cfg.data.H*cfg.data.C),\n","#         transforms.ToTensor(),\n","#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n","#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","#     ]\n","# )\n","\n","fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transform)\n","\n","datasets = dataset_split(fashion_mnist_dataset, split=cfg.train.train_val_split)\n","\n","train_dataset = datasets[\"train\"]\n","val_dataset = datasets[\"val\"]\n","\n","train_batch_size = cfg.train.train_batch_size\n","val_batch_size = cfg.train.val_batch_size\n","test_batch_size = cfg.train.test_batch_size\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=0\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",")\n","test_dataloader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8tljBSaQBZB"},"source":["## 모델 선언 및 손실 함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의 "]},{"cell_type":"code","metadata":{"id":"z8p_hsjsO-on"},"source":["# model define\n","\n","def get_pl_model(cfg: DictConfig, checkpoint_path: Optional[str] = None):\n","\n","    if cfg.model.name == \"MLP\":\n","        model = PLMLP(cfg)\n","    else:\n","        raise NotImplementedError()\n","    \n","    if checkpoint_path is not None:\n","        model = model.load_from_checkpoint(cfg=cfg, checkpoint_path=checkpoint_path)\n","    return model\n","\n","model = get_pl_model(cfg)\n","print(model)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nTzE40svgsB"},"source":["logger = get_loggers(cfg)\n","callbacks = get_callbacks(cfg)\n","\n","trainer = pl.Trainer(\n","    callbacks=callbacks,\n","    logger=logger,\n","    default_root_dir=cfg.train.run_root_dir,\n","    num_sanity_val_steps=2,\n","    **cfg.train.trainer_kwargs\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b93vvDdCv9LZ"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n","\n","trainer.fit(model, train_dataloader, val_dataloader)\n","# trainer.test(model, test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oq-XpcGXQu1v"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n","\n","# define EarlyStopping.\n","early_stopper = EarlyStopping(\n","    patience=3, verbose=True, path=os.path.join(log_model_path, \"model.ckpt\")\n",")\n","\n","# do train with validation.\n","train_step = 0\n","for epoch in range(1, max_epoch+1):\n","    # valid step\n","    with torch.no_grad():\n","        val_loss = 0.0\n","        val_corrects = 0\n","        model.eval()\n","\n","        for val_batch_idx, (val_images, val_labels) in enumerate(\n","            tqdm(val_dataloader, position=0, leave=True, desc=\"validation\")\n","        ):\n","            if gpu is not None:\n","                val_images = val_images.cuda(gpu, non_blocking=True)\n","                val_labels = val_labels.cuda(gpu, non_blocking=True)\n","            # forward\n","            val_outputs = model(val_images)\n","            _, val_preds = torch.max(val_outputs, 1)\n","            \n","            # loss & acc\n","            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0]\n","            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n","    \n","    # valid step logging\n","    val_epoch_loss = val_loss / len(val_dataloader)\n","    val_epoch_acc = val_corrects / len(val_dataloader)\n","    \n","    print(\n","        f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\"\n","    )\n","\n","    # tensorboard log\n","    writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n","    writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n","    writer.add_images(\"Images/val\", val_images, train_step)\n","\n","    # wandb log\n","    wandb.log({\n","        \"Loss/val\": val_epoch_loss,\n","        \"Acc/val\": val_epoch_acc,\n","        \"Images/val\": wandb.Image(val_images),\n","        \"Outputs/val\": wandb.Histogram(val_outputs.detach().cpu().numpy()),\n","        \"Preds/val\": wandb.Histogram(val_preds.detach().cpu().numpy()),\n","        \"Labels/val\": wandb.Histogram(val_labels.data.detach().cpu().numpy()),\n","    }, step=train_step)\n","\n","    # check model early stopping point & save model if the model reached the best performance.\n","    early_stopper(val_epoch_loss, model)\n","    if early_stopper.early_stop:\n","        break\n","    \n","    # train step\n","    current_loss = 0\n","    current_corrects = 0\n","    model.train()\n","\n","    for batch_idx, (images, labels) in enumerate(\n","         tqdm(train_dataloader, position=0, leave=True, desc=\"training\")\n","    ):\n","        if gpu is not None:\n","            images = images.cuda(gpu)\n","            labels = labels.cuda(gpu)\n","\n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        # Backpropagation\n","        # optimizer 초기화 (zero화)\n","        optimizer.zero_grad()\n","\n","        # Perform backward pass\n","        loss.backward()\n","\n","        # Perform Optimization\n","        optimizer.step()\n","\n","        # Perform LR scheduler Work\n","        if scheduler is not None:\n","            scheduler.step()\n","        \n","        current_loss = 0.0\n","        current_corrects = 0\n","\n","        # Forward\n","        # get predictions\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        \n","        # get loss (Loss 계산)\n","        loss = loss_function(outputs, labels)\n","\n","        current_loss += loss.item()\n","        current_corrects += torch.sum(preds == labels.data)\n","\n","        if train_step % log_interval == 0:\n","            train_loss = current_loss / log_interval\n","            train_acc = current_corrects / log_interval\n","\n","            print(\n","                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\"\n","            )\n","            \n","            cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]                \n","\n","            # tensorboard log\n","            writer.add_scalar(\"Loss/train\", train_loss, train_step)\n","            writer.add_scalar(\"Acc/train\", train_acc, train_step)\n","            writer.add_images(\"Images/train\", images, train_step)\n","            writer.add_scalar(\"Learning Rate\", cur_lr, train_step)\n","            writer.add_graph(model, images)\n","\n","            # wandb log\n","            wandb.log({\n","                \"Loss/train\": train_loss,\n","                \"Acc/train\": train_acc,\n","                \"Images/train\": wandb.Image(images),\n","                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n","                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n","                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n","                \"Learning Rate\": cur_lr,\n","            }, step=train_step)\n","\n","            current_loss = 0\n","            current_corrects = 0\n","\n","        train_step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymnDN1VkYOvt"},"source":["# load model\n","loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.02419060841202736-model.ckpt\"))\n","loaded_model.cpu()\n","loaded_model.eval()\n","print(loaded_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UoTf2ztY7nT"},"source":["test_batch_size = 100\n","test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n","\n","test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    # forward\n","    test_outputs = loaded_model(test_images)\n","    _, test_preds = torch.max(test_outputs, 1)\n","\n","    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.detach().numpy())\n","    test_labels_list.extend(test_labels.detach().numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","print(f\"\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0a4PPefaRfH"},"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","\n","final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot.\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","print(\"auc_score\", roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dm5jZ7urbMAO"},"source":[""],"execution_count":null,"outputs":[]}]}