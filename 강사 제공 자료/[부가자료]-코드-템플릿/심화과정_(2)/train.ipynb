{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model\n",
      "start train\n",
      "WARNING:tensorflow:From <ipython-input-1-b23c598ab804>:78: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From /home/irteam/naver/search-env/work/food-fighters/util/metric.py:65: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "3681/3681 [==============================] - 3190s 867ms/step - loss: 0.6801 - binary_accuracy: 0.5907 - batch_recall: 0.0405 - global_recall: 0.0650 - global_kappa: 0.0066 - val_loss: 0.6942 - val_binary_accuracy: 0.5490 - val_batch_recall: 0.1169 - val_global_recall: 0.1407 - val_global_kappa: 0.0603\n",
      "Epoch 2/80\n",
      " 199/3681 [>.............................] - ETA: 50:16 - loss: 0.6747 - binary_accuracy: 0.5834 - batch_recall: 0.0563 - global_recall: 0.0955 - global_kappa: 0.0137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 3179s 864ms/step - loss: 0.6633 - binary_accuracy: 0.5955 - batch_recall: 0.1021 - global_recall: 0.0838 - global_kappa: 0.0302 - val_loss: 0.6826 - val_binary_accuracy: 0.5635 - val_batch_recall: 0.4910 - val_global_recall: 0.7083 - val_global_kappa: 0.0748\n",
      "Epoch 4/80\n",
      "1927/3681 [==============>...............] - ETA: 25:08 - loss: 0.6586 - binary_accuracy: 0.6051 - batch_recall: 0.1773 - global_recall: 0.1594 - global_kappa: 0.0717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555/3681 [===========================>..] - ETA: 1:49 - loss: 0.6450 - binary_accuracy: 0.6310 - batch_recall: 0.2811 - global_recall: 0.2641 - global_kappa: 0.1508"
     ]
    }
   ],
   "source": [
    "import imghdr\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mura.bone_xray_class import Bonemodel\n",
    "from model import classification\n",
    "from util import util_func, metric, loss\n",
    "\n",
    "def main():\n",
    "    #load preprocessed csv file\n",
    "    train_df = pd.read_csv('./bone_xray_train.csv')\n",
    "    valid_df = pd.read_csv('./bone_xray_valid.csv')\n",
    "\n",
    "    #set image size\n",
    "    img_size=512\n",
    "    mura_model=Bonemodel(\"./MURA-v1.1\",img_size)\n",
    "    img_valid, label_valid, path_valid=mura_model.load_validation(valid_df)\n",
    "    print(\"making model\")\n",
    "    img_size=512\n",
    "    #select from [\"densenet121\",\"densenet169\",\"densenet201\",\"resnet50\",\"resnet101\",\"resnet152\"]\n",
    "    model=classification.selectmodel(\"densenet121\",img_size)\n",
    "\n",
    "    # log training time\n",
    "    model_save_path = os.path.join(\"./MURA-v1.1/weight\", \"saved_models\")\n",
    "\n",
    "    # Initiate TensorBoard callback\n",
    "    log_path_name = os.path.join(\"./MURA-v1.1\", \"logs\")\n",
    "    log_path = os.path.join(log_path_name, \"log_{}\".format(img_size))\n",
    "    util_func.create_dir(log_path)\n",
    "\n",
    "    # Initiate checkpoint callback\n",
    "    # save model after success training\n",
    "    util_func.create_dir(model_save_path)\n",
    "    model_path = os.path.join(model_save_path, \"bone_classification_model.h5\")\n",
    "    check_point = keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss',verbose=0,save_best_only=True,save_weights_only=True, mode=\"auto\")\n",
    "    learning_rate=1e-2\n",
    "    decay = learning_rate/10\n",
    "    # Reduce learning rate when a metric has stopped improving.\n",
    "    lr_reduce = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=7,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        min_delta=1e-4,\n",
    "        cooldown=0,\n",
    "        min_lr=0\n",
    "    )\n",
    "\n",
    "    # use binary_crossentropy loss and adam optimizer\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999,epsilon=None, decay=decay, amsgrad=False)\n",
    "\n",
    "    global_recall = metric.BinaryRecall()\n",
    "    global_kappa = metric.BinaryKappa()\n",
    "    weighted_cross_entorpy = loss.WeightedCrossEntropy(train_df)#이걸 loss로씀\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam,\n",
    "    metrics=[keras.metrics.binary_accuracy, metric.batch_recall, global_recall, global_kappa])\n",
    "\n",
    "    # start training\n",
    "    batch_size=10 #set batch size\n",
    "    epochs=80 #set epochs\n",
    "\n",
    "    print(\"start train\")\n",
    "    train_history = model.fit_generator(\n",
    "        mura_model.input_generator(train_df, batch_size, mura_model.prepare_imggen(train_df)),\n",
    "        steps_per_epoch=math.ceil(train_df.shape[0] / batch_size),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(img_valid, label_valid),\n",
    "        callbacks=[check_point, lr_reduce],\n",
    "      )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
